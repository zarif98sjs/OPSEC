{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Get parent working directory\n",
    "from pathlib import Path\n",
    "parent = Path.cwd().parents[1]\n",
    "parent\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "encoder = hub.load(str(parent / 'Methods/universal-sentence-encoder_4'))\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"news_small1\", \"news_small2\", \"news_small3\", \\\n",
    "            \"tweets_small1\", \"tweets_small2\", \"tweets_small3\", \\\n",
    "            \"stack_small1\", \"stack_small2\", \"stack_small3\", \\\n",
    "            \"quora_small1\", \"quora_small2\", \"quora_small3\", \\\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_opsec(dataset):\n",
    "    file_path= parent / 'Data' / dataset\n",
    "\n",
    "    docids = list()\n",
    "    news_labels = list()\n",
    "    questions = []\n",
    "\n",
    "    with open(file_path) as fp:\n",
    "        lines = fp.read().split(\"\\n\")\n",
    "        for line in lines:\n",
    "            if line:\n",
    "                docid = json.loads(line)[\"Id\"]\n",
    "                label = json.loads(line)[\"clusterNo\"]\n",
    "                text = json.loads(line)[\"textCleaned\"]\n",
    "                docids.append(docid)\n",
    "                news_labels.append(label)\n",
    "                questions.append(text)\n",
    "                \n",
    "    startTime = time.time()   \n",
    "    clus = {}\n",
    "    cluid = 0\n",
    "    alpha = 0.35\n",
    "    assignid = []\n",
    "    for i, q in enumerate(questions):\n",
    "        if clus:\n",
    "            maxsim = -np.inf\n",
    "            addclu = -np.inf\n",
    "            emb = encoder([q])\n",
    "            for clu in clus:\n",
    "                sim = np.inner(emb, clus[clu]['cent']) \n",
    "                if sim > maxsim:\n",
    "                    maxsim = sim\n",
    "                    addclu = clu\n",
    "            if (maxsim > alpha):\n",
    "                clus[addclu]['docid'].append(docids[i])\n",
    "                clus[addclu]['doc'].append(q)\n",
    "                clus[addclu]['cent'] = np.mean(np.vstack([emb, clus[addclu]['cent']]), axis=0)\n",
    "                assignid.append(addclu)\n",
    "            else:\n",
    "                clus[cluid] = {'docid': [docid], 'doc': [q], 'cent': encoder([q])}\n",
    "                assignid.append(cluid)\n",
    "                cluid+=1   \n",
    "        else:\n",
    "            clus[cluid] = {'docid': [docid], 'doc': [q], 'cent': encoder([q])}\n",
    "            assignid.append(cluid)\n",
    "            cluid+=1\n",
    "    endTime = time.time()\n",
    "    runtime = endTime - startTime\n",
    "    \n",
    "    outputPath = 'results/' + dataset + '.txt'\n",
    "\n",
    "    writer = open(outputPath, 'w')\n",
    "    writer.write(\"0 \" + str(runtime) + \"\\n\")\n",
    "    for i, docid in enumerate(docids):\n",
    "        documentID = docid\n",
    "        cluster = assignid[i]\n",
    "        writer.write(str(documentID) + \" \" + str(cluster) + \"\\n\")\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    run_opsec(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
